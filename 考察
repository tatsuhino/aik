対象とするデータは、検索途中のコンテンツなのか、求めていたコンテンツなのかが明確に分かれている必要がある。
その二つの条件を満たすデータとして、kaggleで公開されていたECサイトのデータを利用した。
検索途中のコンテンツ⇒View,求めていたコンテンツ⇒addToCart


■処理プロセス
・どうやって評価するか。
・ECサイトのデータを使用し、ユーザの評価履歴に対して、ゴールのデータがどれだけ充てられるかを、
協調フィルタリング、Doc2vecを利用した場合で比較した。
・

■データ準備
公開データの形式のままでは利用できないので、履歴順になるように整形
■整形
レコメンド問題のよくある設定として、user,itemに対して良い、悪いのスコアが与えられている。
暗黙的フィードバックをスコアリング　同一のユーザがなどもリピートしていれば高スコア

■モデル構築​
ベクトルの次元数、エポック数などを比較し、最も高い結果となったものを採用。
図いる？
■評価​
データ分割して、交差検証した。
何をもってHITと判断したのかの説明。上位10件


■結果棒グラフ

結果	結果	"協調フィルタリング＜Doc2Vec？の結果になった。
ただし、Doc2Vecの場合でもそこまで確率は高くなかった。
"	"以下の３パターンで精度を比較
・よく買われているアイテムの上位何件
・協調フィルタリングのユーザベース
・Doc2Vec
・Doc2Vec(アイテムベース


■考察
協調フィルタリング：
メモリ

Doc2Vec：
モデルを可視化したら、最初の仮説が怪しいことが見えてきた。
一方で、ベクトルの次元数が大幅に少ないため、少なりリソースでリアルアイム処理をする場合は有効

データを精査して可視化してみると、バラバラだったことが分かった。
本当に欲しい、ゴールにたどり着くまでの


■今後の課題
①の中での振り返り

②をするにあたっての課題
ナレッジ検索では、検索途中のコンテンツなのか、求めていたコンテンツなのかがそのままでは明確に判断つかないので、閲覧時間や閲覧回数、いいねボタンなどで判断する必要がある。
コールドスタート問題→コンテンツベースのレコメンドを


データの違い
・kaggle,deepanalytisなど、オープンデータを取得するプラットフォームができあがっているので、
学習、手を動かすうえでの敷居は下がっている。
・一方でデータの特性については注意が必要。

世の中にあるような協調フィルタリングのサンプルでは、
評価レートがあるものがほとんど。ユーザが明示的に
暗黙的フィードバックなため、良い、悪いが明示されていない。

■研究を通じて学んだこと

成果：機械学習をする上での処理プロセスを一通り学んだ。
基本的なレコメンドアルゴリズムについて知識を身に着けた。


データの精査を早い段階でやること（それをするためにも可視化が大事。
割と簡単。pythonも今回初めて触れたが、とっつきやすい。一般的によくやられている処理についてはライブラリも充実しているのですぐできる。
一方で、新しいことをやろうとした場合だったり、細かいチューニングをする場合はやっぱり知見がないと厳しい。
数学的な背景を知らないままでは、あるものを使うことしかできない。



